{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "id": "8zloECyTntYL",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Semi-supervised image classification using contrastive pretraining with SimCLR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5LFxiHFntYP"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UsEAhpOsntYP"
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "\n",
    "\n",
    "# Make sure we are able to handle large datasets\n",
    "import resource\n",
    "\n",
    "low, high = resource.getrlimit(resource.RLIMIT_NOFILE)\n",
    "resource.setrlimit(resource.RLIMIT_NOFILE, (high, high))\n",
    "\n",
    "import math\n",
    "\n",
    "import keras\n",
    "\n",
    "%matplotlib widget\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from keras import layers\n",
    "from keras import optimizers as ops\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Set seed for evaluation purpose (remove in production)\n",
    "keras.utils.set_random_seed(5)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(5)\n",
    "os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"1\"\n",
    "np.random.seed(5)\n",
    "tf.random.set_seed(5)\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfHfEU0WntYQ"
   },
   "source": [
    "## Hyperparameter setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYiAk4QOntYQ"
   },
   "outputs": [],
   "source": [
    "# Dataset hyperparameters\n",
    "unlabeled_dataset_size = sum(\n",
    "    [len(files) for r, d, files in os.walk(\"../data_ssl/unlabeled/\")]\n",
    ")\n",
    "labeled_dataset_size = sum(\n",
    "    [len(files) for r, d, files in os.walk(\"../data_ssl/train/\")]\n",
    ")\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "width = 224\n",
    "\n",
    "print(\"Unlabeled Images: \" + str(unlabeled_dataset_size))\n",
    "print(\"Labeled Images: \" + str(labeled_dataset_size))\n",
    "\n",
    "# Algorithm hyperparameters\n",
    "num_epochs = 30\n",
    "batch_size = 20\n",
    "temperature = 0.1\n",
    "\n",
    "# Stronger augmentations for contrastive, weaker ones for supervised training\n",
    "contrastive_augmentation = {\"min_area\": 0.3, \"brightness\": 0.6, \"jitter\": 0.2}\n",
    "classification_augmentation = {\n",
    "    \"min_area\": 0.75,\n",
    "    \"brightness\": 0.3,\n",
    "    \"jitter\": 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wOoK85X1ntYQ"
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J4h27xPSntYR"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset():\n",
    "    # Labeled and unlabeled samples are loaded synchronously\n",
    "    # with batch sizes selected accordingly\n",
    "    steps_per_epoch = (unlabeled_dataset_size + labeled_dataset_size) // batch_size\n",
    "    unlabeled_batch_size = unlabeled_dataset_size // steps_per_epoch\n",
    "    labeled_batch_size = labeled_dataset_size // steps_per_epoch\n",
    "    print(\n",
    "        f\"batch size is {unlabeled_batch_size} (unlabeled) + {labeled_batch_size} (labeled)\"\n",
    "    )\n",
    "\n",
    "    labeled_train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"../data_ssl/train/\",\n",
    "        validation_split=0.2,\n",
    "        subset=\"both\",\n",
    "        seed=5,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        label_mode=\"int\"\n",
    "    )\n",
    "\n",
    "    unlabeled_train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"../data_ssl/unlabeled/\",\n",
    "        label_mode=None,\n",
    "        seed=5,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True\n",
    "    )\n",
    "\n",
    "    test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "        \"../data_ssl/test_labeled/\",\n",
    "        seed=5,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        color_mode=\"rgb\",\n",
    "        label_mode=\"int\"\n",
    "    )\n",
    "\n",
    "    # Labeled and unlabeled datasets are zipped together\n",
    "    train_dataset = tf.data.Dataset.zip(\n",
    "        (unlabeled_train_ds, labeled_train_ds)\n",
    "    ).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_dataset, labeled_train_ds, test_dataset, val_ds\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "train_dataset, labeled_train_dataset, test_dataset, validation_dataset = (\n",
    "    prepare_dataset()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CF68BiqsntYR"
   },
   "source": [
    "## Image augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pl7k3VrpntYR"
   },
   "outputs": [],
   "source": [
    "# Distorts the color distibutions of images\n",
    "class RandomColorAffine(layers.Layer):\n",
    "    def __init__(self, brightness=0, jitter=0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.brightness = brightness\n",
    "        self.jitter = jitter\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"brightness\": self.brightness, \"jitter\": self.jitter})\n",
    "        return config\n",
    "\n",
    "    def call(self, images, training=True):\n",
    "        if training:\n",
    "            batch_size = tf.shape(images)[0]\n",
    "\n",
    "            # Same for all colors\n",
    "            brightness_scales = 1 + tf.random.uniform(\n",
    "                (batch_size, 1, 1, 1),\n",
    "                minval=-self.brightness,\n",
    "                maxval=self.brightness,\n",
    "            )\n",
    "            # Different for all colors\n",
    "            jitter_matrices = tf.random.uniform(\n",
    "                (batch_size, 1, 3, 3), minval=-self.jitter, maxval=self.jitter\n",
    "            )\n",
    "\n",
    "            color_transforms = (\n",
    "                tf.eye(3, batch_shape=[batch_size, 1])\n",
    "                * brightness_scales\n",
    "                # + jitter_matrices // removed color change\n",
    "            )\n",
    "            images = tf.clip_by_value(tf.matmul(images, color_transforms), 0, 1)\n",
    "        return images\n",
    "\n",
    "\n",
    "# Image augmentation module\n",
    "def get_augmenter(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - math.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Rescaling(1 / 255),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def get_augmenter_without_pooling(min_area, brightness, jitter):\n",
    "    zoom_factor = 1.0 - math.sqrt(min_area)\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Rescaling(1 / 255),\n",
    "            layers.RandomFlip(\"horizontal\"),\n",
    "            layers.RandomTranslation(zoom_factor / 2, zoom_factor / 2),\n",
    "            layers.RandomZoom((-zoom_factor, 0.0), (-zoom_factor, 0.0)),\n",
    "            RandomColorAffine(brightness, jitter),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def visualize_augmentations(num_images):\n",
    "    # Sample a batch from a dataset\n",
    "    images = next(iter(train_dataset))[0][:num_images]\n",
    "\n",
    "    # Apply augmentations\n",
    "    augmented_images = zip(\n",
    "        keras.Sequential([layers.Rescaling(1 / 255)])(images),\n",
    "        get_augmenter_without_pooling(**classification_augmentation)(images),\n",
    "        get_augmenter_without_pooling(**contrastive_augmentation)(images),\n",
    "        get_augmenter_without_pooling(**contrastive_augmentation)(images),\n",
    "    )\n",
    "    row_titles = [\n",
    "        \"Original:\",\n",
    "        \"Weakly augmented:\",\n",
    "        \"Strongly augmented:\",\n",
    "        \"Strongly augmented:\",\n",
    "    ]\n",
    "    plt.figure(figsize=(num_images * 1.3, 4 * 1.3), dpi=100)\n",
    "    for column, image_row in enumerate(augmented_images):\n",
    "        for row, image in enumerate(image_row):\n",
    "            plt.subplot(4, num_images, row * num_images + column + 1)\n",
    "            plt.imshow(image)\n",
    "            if column == 0:\n",
    "                plt.title(row_titles[row], loc=\"left\")\n",
    "            plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "visualize_augmentations(num_images=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mxXd-sE_ntYS"
   },
   "source": [
    "## Encoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "id": "PjA8EQl3ntYS",
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pretrained models\n",
    "base_finetuned_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "    input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\", pooling=\"avg\"\n",
    ")\n",
    "base_finetuned_model.trainable = True\n",
    "\n",
    "# Define encoder\n",
    "def get_encoder():\n",
    "    # return resnet_simclr // this needs a lot of GPU/RAM capacity\n",
    "    return keras.Sequential(\n",
    "        [\n",
    "            layers.Input(shape=(224, 224, 3)),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Conv2D(width, kernel_size=3, strides=2, activation=\"relu\"),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(width, activation=\"relu\"),\n",
    "        ],\n",
    "        name=\"encoder\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NWwjJX0pntYS"
   },
   "source": [
    "## Supervised baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tK9FwctOntYT"
   },
   "outputs": [],
   "source": [
    "# Baseline supervised training with random initialization\n",
    "pretrained_model = tf.keras.applications.efficientnet_v2.EfficientNetV2S(\n",
    "    input_shape=(224, 224, 3), include_top=False, weights=\"imagenet\", pooling=\"avg\"\n",
    ")\n",
    "pretrained_model.trainable = False\n",
    "\n",
    "inputs = pretrained_model.input\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(pretrained_model.output)\n",
    "x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "x = tf.keras.layers.Dropout(0.4)(x)\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "outputs = tf.keras.layers.Dense(7, activation=\"softmax\")(x)\n",
    "baseline_model = tf.keras.Model(\n",
    "    inputs,\n",
    "    outputs,\n",
    "    name=\"baseline_model\",\n",
    ")\n",
    "\n",
    "# Compile baseline_model\n",
    "baseline_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "]\n",
    "\n",
    "# Fit baseline_model\n",
    "baseline_history = baseline_model.fit(\n",
    "    labeled_train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(baseline_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7DXAQJkAntYT"
   },
   "source": [
    "## Self-supervised model for contrastive pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9SXehP8NntYT"
   },
   "outputs": [],
   "source": [
    "# Define the contrastive model (SimCLR) with model-subclassing\n",
    "class ContrastiveModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.temperature = temperature\n",
    "        self.contrastive_augmenter = get_augmenter(**contrastive_augmentation)\n",
    "        self.classification_augmenter = get_augmenter(**classification_augmentation)\n",
    "        self.encoder = get_encoder()\n",
    "        # Non-linear MLP as projection head\n",
    "        self.projection_head = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=(width,)),\n",
    "                layers.Dense(width, activation=\"relu\"),\n",
    "                layers.Dense(width),\n",
    "            ],\n",
    "            name=\"projection_head\",\n",
    "        )\n",
    "        # Single dense layer for linear probing\n",
    "        self.linear_probe = keras.Sequential(\n",
    "            [layers.Input(shape=(width,)), layers.Dense(7)],\n",
    "            name=\"linear_probe\",\n",
    "        )\n",
    "\n",
    "        self.encoder.summary()\n",
    "        self.projection_head.summary()\n",
    "        self.linear_probe.summary()\n",
    "\n",
    "    def compile(self, contrastive_optimizer, probe_optimizer, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "\n",
    "        self.contrastive_optimizer = contrastive_optimizer\n",
    "        self.probe_optimizer = probe_optimizer\n",
    "\n",
    "        # self.contrastive_loss will be defined as a method\n",
    "        self.probe_loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "        self.contrastive_loss_tracker = keras.metrics.Mean(name=\"c_loss\")\n",
    "        self.contrastive_accuracy = keras.metrics.SparseCategoricalAccuracy(\n",
    "            name=\"c_acc\"\n",
    "        )\n",
    "        self.probe_loss_tracker = keras.metrics.Mean(name=\"p_loss\")\n",
    "        self.probe_accuracy = keras.metrics.SparseCategoricalAccuracy(name=\"p_acc\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.contrastive_loss_tracker,\n",
    "            self.contrastive_accuracy,\n",
    "            self.probe_loss_tracker,\n",
    "            self.probe_accuracy,\n",
    "        ]\n",
    "\n",
    "    def contrastive_loss(self, projections_1, projections_2):\n",
    "        # InfoNCE loss (information noise-contrastive estimation)\n",
    "        # NT-Xent loss (normalized temperature-scaled cross entropy)\n",
    "\n",
    "        # Cosine similarity: the dot product of the l2-normalized feature vectors\n",
    "        projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n",
    "        projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n",
    "        similarities = (\n",
    "            tf.matmul(projections_1, projections_2, transpose_b=True) / self.temperature\n",
    "        )\n",
    "\n",
    "        # The similarity between the representations of two augmented views of the\n",
    "        # same image should be higher than their similarity with other views\n",
    "        batch_size = tf.shape(projections_1)[0]\n",
    "        contrastive_labels = tf.range(batch_size)\n",
    "        self.contrastive_accuracy.update_state(contrastive_labels, similarities)\n",
    "        self.contrastive_accuracy.update_state(\n",
    "            contrastive_labels, tf.transpose(similarities)\n",
    "        )\n",
    "\n",
    "        # The temperature-scaled similarities are used as logits for cross-entropy\n",
    "        # a symmetrized version of the loss is used here\n",
    "        loss_1_2 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, similarities, from_logits=True\n",
    "        )\n",
    "        loss_2_1 = keras.losses.sparse_categorical_crossentropy(\n",
    "            contrastive_labels, tf.transpose(similarities), from_logits=True\n",
    "        )\n",
    "        return (loss_1_2 + loss_2_1) / 2\n",
    "\n",
    "    def train_step(self, data):\n",
    "        (unlabeled_images), (labeled_images, labels) = data\n",
    "\n",
    "        # Both labeled and unlabeled images are used, without labels\n",
    "        images = tf.concat((unlabeled_images, labeled_images), axis=0)\n",
    "        # Each image is augmented twice, differently\n",
    "        augmented_images_1 = self.contrastive_augmenter(images, training=True)\n",
    "        augmented_images_2 = self.contrastive_augmenter(images, training=True)\n",
    "        with tf.GradientTape() as tape:\n",
    "            features_1 = self.encoder(augmented_images_1, training=True)\n",
    "            features_2 = self.encoder(augmented_images_2, training=True)\n",
    "            # The representations are passed through a projection mlp\n",
    "            projections_1 = self.projection_head(features_1, training=True)\n",
    "            projections_2 = self.projection_head(features_2, training=True)\n",
    "            contrastive_loss = self.contrastive_loss(projections_1, projections_2)\n",
    "        gradients = tape.gradient(\n",
    "            contrastive_loss,\n",
    "            self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "        )\n",
    "        self.contrastive_optimizer.apply_gradients(\n",
    "            zip(\n",
    "                gradients,\n",
    "                self.encoder.trainable_weights + self.projection_head.trainable_weights,\n",
    "            )\n",
    "        )\n",
    "        self.contrastive_loss_tracker.update_state(contrastive_loss)\n",
    "\n",
    "        # Labels are only used in evalutation for an on-the-fly logistic regression\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=True\n",
    "        )\n",
    "        with tf.GradientTape() as tape:\n",
    "            # the encoder is used in inference mode here to avoid regularization\n",
    "            # and updating the batch normalization paramers if they are used\n",
    "            features = self.encoder(preprocessed_images, training=False)\n",
    "            class_logits = self.linear_probe(features, training=True)\n",
    "            probe_loss = self.probe_loss(labels, class_logits)\n",
    "        gradients = tape.gradient(probe_loss, self.linear_probe.trainable_weights)\n",
    "        self.probe_optimizer.apply_gradients(\n",
    "            zip(gradients, self.linear_probe.trainable_weights)\n",
    "        )\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, data):\n",
    "        labeled_images, labels = data\n",
    "\n",
    "        # For testing the components are used with a training=False flag\n",
    "        preprocessed_images = self.classification_augmenter(\n",
    "            labeled_images, training=False\n",
    "        )\n",
    "        features = self.encoder(preprocessed_images, training=False)\n",
    "        class_logits = self.linear_probe(features, training=False)\n",
    "        probe_loss = self.probe_loss(labels, class_logits)\n",
    "        self.probe_loss_tracker.update_state(probe_loss)\n",
    "        self.probe_accuracy.update_state(labels, class_logits)\n",
    "\n",
    "        # Only the probe metrics are logged at test time\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}\n",
    "\n",
    "\n",
    "# Contrastive pretraining\n",
    "pretraining_model = ContrastiveModel()\n",
    "pretraining_model.compile(\n",
    "    contrastive_optimizer=keras.optimizers.Adam(),\n",
    "    probe_optimizer=keras.optimizers.Adam(),\n",
    ")\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_p_loss\", patience=5, restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "]\n",
    "\n",
    "# Fit pretraining_model\n",
    "pretraining_history = pretraining_model.fit(\n",
    "    train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(pretraining_history.history[\"val_p_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kt2BxmYrntYT"
   },
   "source": [
    "## Supervised finetuning of the pretrained encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JOykQ-K5ntYT"
   },
   "outputs": [],
   "source": [
    "# Supervised finetuning of the pretrained encoder\n",
    "finetuning_model = keras.Sequential(\n",
    "    [\n",
    "        pretraining_model.encoder,\n",
    "        layers.Dense(7),\n",
    "    ],\n",
    "    name=\"finetuning_model\",\n",
    ")\n",
    "\n",
    "# Compile finetuning_model\n",
    "finetuning_model.compile(\n",
    "    optimizer=keras.optimizers.Adam(),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy(name=\"acc\")],\n",
    ")\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\", patience=5, restore_best_weights=True\n",
    "    ),\n",
    "    tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1),\n",
    "]\n",
    "\n",
    "# Fit finetuning_model\n",
    "finetuning_history = finetuning_model.fit(\n",
    "    labeled_train_dataset,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    ")\n",
    "\n",
    "# Save model for later use\n",
    "finetuning_model.save(\"ssl_model_finetuned.keras\")\n",
    "\n",
    "print(\n",
    "    \"Maximal validation accuracy: {:.2f}%\".format(\n",
    "        max(finetuning_history.history[\"val_acc\"]) * 100\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iWvBqrhQntYU"
   },
   "source": [
    "## Comparison against the baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5qrftllntYU"
   },
   "outputs": [],
   "source": [
    "# The classification accuracies of the baseline and the pretraining + finetuning process:\n",
    "def plot_training_curves(pretraining_history, finetuning_history, baseline_history):\n",
    "    for metric_key, metric_name in zip([\"acc\", \"loss\"], [\"accuracy\", \"loss\"]):\n",
    "        plt.figure(figsize=(8, 5), dpi=100)\n",
    "        plt.plot(\n",
    "            baseline_history.history[f\"val_{metric_key}\"],\n",
    "            label=\"supervised baseline\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            pretraining_history.history[f\"val_p_{metric_key}\"],\n",
    "            label=\"self-supervised pretraining\",\n",
    "        )\n",
    "        plt.plot(\n",
    "            finetuning_history.history[f\"val_{metric_key}\"],\n",
    "            label=\"supervised finetuning\",\n",
    "        )\n",
    "        plt.legend()\n",
    "        plt.title(f\"Classification {metric_name} during training\")\n",
    "        plt.xlabel(\"epochs\")\n",
    "        plt.ylabel(f\"validation {metric_name}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "plot_training_curves(pretraining_history, finetuning_history, baseline_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the base model\n",
    "results_baseline = baseline_model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Baseline Test Accuracy: {np.round(results_baseline[1] * 100,2)}%\")\n",
    "# Evaluate the finetuned model\n",
    "results_finetuned = finetuning_model.evaluate(test_dataset, verbose=0)\n",
    "print(f\"Finetuned Test Accuracy: {np.round(results_finetuned[1] * 100,2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data_ssl/train/\"\n",
    "labels = sorted(\n",
    "    [name for name in os.listdir(folder) if os.path.isdir(os.path.join(folder, name))]\n",
    ")\n",
    "\n",
    "y_pred_baseline = []  # store predicted labels\n",
    "y_pred_finetuned = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_dataset:  # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = baseline_model.predict(image_batch, verbose=0)\n",
    "    # append predicted labels\n",
    "    y_pred_baseline.append(np.argmax(preds, axis=-1))\n",
    "\n",
    "    # compute predictions\n",
    "    preds = finetuning_model.predict(image_batch, verbose=0)\n",
    "    # append predicted labels\n",
    "    y_pred_finetuned.append(np.argmax(preds, axis=-1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis=0)\n",
    "predicted_labels_baseline = tf.concat([item for item in y_pred_baseline], axis=0)\n",
    "predicted_labels_finetuned = tf.concat([item for item in y_pred_finetuned], axis=0)\n",
    "\n",
    "# Generate reports\n",
    "matrix_baseline = confusion_matrix(correct_labels, predicted_labels_baseline)\n",
    "matrix_finetuned = confusion_matrix(correct_labels, predicted_labels_finetuned)\n",
    "report_baseline = classification_report(\n",
    "    correct_labels,\n",
    "    predicted_labels_baseline,\n",
    "    target_names=labels,\n",
    "    zero_division=0,\n",
    ")\n",
    "report_finetuned = classification_report(\n",
    "    correct_labels,\n",
    "    predicted_labels_finetuned,\n",
    "    target_names=labels,\n",
    "    zero_division=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(matrix_baseline, annot=True, cmap=\"viridis\", fmt=\"g\")\n",
    "plt.xticks(ticks=np.arange(7) + 0.5, labels=labels, rotation=90)\n",
    "plt.yticks(ticks=np.arange(7) + 0.5, labels=labels, rotation=0)\n",
    "plt.title(\"Confusion Matrix (Baseline)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(matrix_finetuned, annot=True, cmap=\"viridis\", fmt=\"g\")\n",
    "plt.xticks(ticks=np.arange(7) + 0.5, labels=labels, rotation=90)\n",
    "plt.yticks(ticks=np.arange(7) + 0.5, labels=labels, rotation=0)\n",
    "plt.title(\"Confusion Matrix (Finetuned)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print classification report\n",
    "print(\"Classification Report (Baseline):\\n\", report_baseline)\n",
    "print(\"Classification Report (Finetuned):\\n\", report_finetuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "semisupervised_simclr",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
